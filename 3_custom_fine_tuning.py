# -*- coding: utf-8 -*-
"""3_Custom Fine-tuning

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IIhwljwVa3Hd_6Q2gNnkkwgp1n6yXnr1

This notebook describes a simple case of finetuning. You can finetune either the `twitter-roberta-base` (https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m) language model, or `twitter-roberta-base-sentiment` (https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest), which has already been fine-tuned on sentiment analysis English twitter data.

This notebook was modified from https://huggingface.co/transformers/v3.2.0/custom_datasets.html

# Fine-tuning and Evaluation of Language Models

Install necessary libraries
"""

# !pip install datasets
# !pip install transformers

"""Import relevant libraries"""

from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback, set_seed
from sklearn.metrics import classification_report
import datasets
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

plt.rc("font", size=25)

"""# Parameters

one has to consider before training a transformer model including:
- The learning rate (LR) which indicates how fast the model's weights are going to be updated (larger values results in faster training)
- The number of epochs (EPOCHS) indicating how many times the model will go through the train data (1 epoch means that the model will see the train set only once).
- The batch size (BATCH_SIZE) indicating the number of samples that will be pass through to the model at one time.

There many other hyper-parameters that you can experiment with such as `weight_decay` and `warmup_ratio` (find more at: https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/trainer#transformers.TrainingArguments) and feel free to experiment with them but depending on your understanding of the models used it may be best to use the default values provided.
"""

LR = 2e-5
EPOCHS = 30
BATCH_SIZE = 64
MODEL = "cardiffnlp/twitter-roberta-base-2021-124m" # use this to finetune the language model
#MODEL = "cardiffnlp/twitter-roberta-base-sentiment-latest" # use this to finetune the sentiment classifier
MAX_TRAINING_EXAMPLES = 7500 # set this to -1 if you want to use the whole training set

"""As the models are non-deterministic (i.e. can produce different results even if trained on the same dataset) we can set a seed so we can reproduce our experiments. In this notebook we are going to use the seed 223."""

# set transformers seed
seed = 223
set_seed(seed)

"""# Data
We will be utilizing the the sentiment dataset for the TweetEval benchmark however feel free to use your own dataset if you prefer!

## Option 1: Download the dataset from CardiffNLP's github.

Loading TweetEval dataset for the sentiment task.
Also available tasks for:
- Emoji Prediction (emoji)
- Emotion Recognition (emotion)
- Hate Speech Detection (hate)
- Irony Detection (irony)
- Offensive Language Identification (offensive)
- Stance Detection (stance)

See: https://github.com/cardiffnlp/tweeteval/tree/main/datasets for more details
"""

task = "sentiment"

files = """test_labels.txt
test_text.txt
train_labels.txt
train_text.txt
val_labels.txt
val_text.txt""".split('\n')

for f in files:
  p = f"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/{f}"
  !wget $p

"""We now read the data from the files we donwloaded, format the data in a more usable structure and create the train, validation, and test sets  i.e. ``` { 'train': { 'text': ['foobar', ...], 'labels': [0, ...] }, ... } ```.

"""

dataset_dict = {}
for i in ['train','val','test']:
  dataset_dict[i] = {}
  for j in ['text','labels']:
    dataset_dict[i][j] = open(f"{i}_{j}.txt").read().split('\n')[:-1] # ignore last line of file
    if j == 'labels':
      dataset_dict[i][j] = [int(x) for x in dataset_dict[i][j]]

if MAX_TRAINING_EXAMPLES > 0:
  dataset_dict['train']['text']=dataset_dict['train']['text'][:MAX_TRAINING_EXAMPLES]
  dataset_dict['train']['labels']=dataset_dict['train']['labels'][:MAX_TRAINING_EXAMPLES]

# Transform dictionaries to datasets.Dataset for easier preprocessing (https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html#from-a-python-dictionary)
train_dataset = datasets.Dataset.from_dict(dataset_dict['train'])
val_dataset = datasets.Dataset.from_dict(dataset_dict['val'])
test_dataset = datasets.Dataset.from_dict(dataset_dict['test'])

"""Initialize and use model's tokenizer to get the text encodings."""

tokenizer = AutoTokenizer.from_pretrained(f, use_fast=True)

train_dataset = train_dataset.map(lambda e: tokenizer(e['text'], truncation=True), batched=True)
val_dataset = val_dataset.map(lambda e: tokenizer(e['text'], truncation=True), batched=True)
test_dataset = test_dataset.map(lambda e: tokenizer(e['text'], truncation=True), batched=True)

"""## Option 2: Download the dataset directly from huggingface (https://huggingface.co/datasets/tweet_eval)."""

# load dataset using 'datasets' library by specifying the name of the dataset and the subset (task).
task = 'sentiment'
dataset = datasets.load_dataset('tweet_eval', task)

#df['Sentiment']=df['Sentiment'].replace({-2: 'Extremely Negative',-1: 'Negative', 0: 'Neutral', 1:'Positive', 2:'Extremely Positive'})
#df2 = df.to_dict('records')

from datasets import DatasetDict
from datasets import load_dataset
imdb = load_dataset('csv', data_files='semeval2017_football2.csv')

# 90% train, 10% test + validation
train_testvalid = imdb["train"].train_test_split(test_size=0.1)
# Split the 10% test + valid in half test, half valid
test_valid = train_testvalid['test'].train_test_split(test_size=0.5)
# gather everyone if you want to have a single DatasetDict
dataset = DatasetDict({
    'train': train_testvalid['train'],
    'test': test_valid['test'],
    'validation': test_valid['train']})

dataset

# use model's tokenizer to get text encodings
tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)

dataset =dataset.map(lambda e: tokenizer(e['text'], truncation=True), batched=True)

# make sure to use whole train dataset if MAX_TRAINING_EXAMPLES == -1
if MAX_TRAINING_EXAMPLES == -1: MAX_TRAINING_EXAMPLES = dataset['train'].shape[0]
# split into train/val/test sets
train_dataset = dataset['train']
val_dataset = dataset['validation']
test_dataset = dataset['test']

print(dataset['train'][3])
print(dataset['test'])
print(dataset['validation'])

!pip install accelerate -U

"""# Fine-tuning

The steps above prepared the datasets in the way that the trainer is expected. Now all we need to do is create a model
to fine-tune, define the `TrainingArguments`/`TFTrainingArguments` and
instantiate a `Trainer`/`TFTrainer`.

More information about the Trainer's arguments can be be found here: https://huggingface.co/docs/transformers/v4.20.0/en/main_classes/trainer#transformers.TrainingArguments
"""

training_args = TrainingArguments(
    output_dir='./results',                   # output directory
    num_train_epochs=EPOCHS,                  # total number of training epochs
    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training
    per_device_eval_batch_size=BATCH_SIZE,    # batch size for evaluation
    warmup_steps=100,                          # number of warmup steps for learning rate scheduler
    weight_decay=0.01,                        # strength of weight decay
    logging_dir='./logs',                     # directory for storing logs
    logging_steps=160,                         # when to print log
    evaluation_strategy='steps',              # evaluate every n number of steps.
    eval_steps=160,                            # how often to evaluate. If not set defaults to number of logging_steps
    load_best_model_at_end=True,              # to load or not the best model at the end
    save_steps=160,                            # create a checkpoint every time we evaluate,
    seed=seed                                 # seed for consistent results

)


num_labels = len(set(train_dataset['labels'])) if 'labels' in train_dataset.features.keys() else len(set(train_dataset['label']))

model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=num_labels)

trainer = Trainer(
    model=model,                              # the instantiated ðŸ¤— Transformers model to be trained
    tokenizer=tokenizer,                      # tokenizer to be used to pad the inputs
    args=training_args,                       # training arguments, defined above
    train_dataset=train_dataset,              # training dataset
    eval_dataset=val_dataset,                  # evaluation dataset
    callbacks = [EarlyStoppingCallback(3, 0.001)], # early stopping which stops the training after 3 evaluation calls with no improvement of performance of at least 0.001
)

trainer.train()

"""Tip: In cases where you are facing memory issue during training try a smaller batch size."""

trainer.save_model("./results/best_model") # save best model

"""# Evaluate on Test set"""

# for every prediction the model ouptuts logits where largest value indicates the predicted class
test_preds_raw, test_labels , _ = trainer.predict(test_dataset)
test_preds = np.argmax(test_preds_raw, axis=-1)
print(classification_report(test_labels, test_preds, digits=3))

"""We can also check how "sure" the model is for every prediction by getting the softmax scores for each prediction."""

from scipy.special import softmax

scores = softmax(test_preds_raw, axis=1)
scores

"""# Make predictions on unseen tweets

We are going to apply the model we trained on tweets made by the Prime Ministers of UK (Boris Johnson) and Australia (Anthony Albanese) and their respective oppossition leaders (Keir Starmer & Scott Morrison). Tweets were extracted from January 1 2022 to June 19 2022.

You can find more details on how to extract tweets using the Twiiter api in this notebook: https://colab.research.google.com/drive/1RyiRY3aCUQ_K-PiXp1qN-8l7479uQa9f.

Download and load the dataset in a pandas Dataframe.
"""

!gdown https://drive.google.com/uc?id=1EN1jGxwprKxvzV2D4ML3dFp1fMlSrXEb

"""First we will see how to get predictions using a custom function."""

def get_predictions(tweets):
  """ wrapper function to predict sentiment of tweets"""
  with torch.no_grad():
    encoded_input = tokenizer(
        tweets, padding=True, truncation=True, return_tensors='pt'
    )

    # set model on evaluation mode to deactivate Dropout
    trainer.model.eval()
    # pass encoded text to model
    output = trainer.model(**{k: v.to('cuda') for k, v in encoded_input.items()})
    # get logits and move them to cpu to get the predictions
    output = output.logits.detach().cpu().numpy()
    predictions = np.argmax(output, axis=1)

  return predictions

tweets = ["RT @UKLabour: Britain is facing the biggest rail strike in a generation but @GrantShapps hasnâ€™t spent a single second in talks to avert itâ€¦",
          "Good news in todayâ€™s jobs stats: the number of employees on payrolls increased again in March.",
          "I'm #live in Gladstone with my Labor team: https://t.co/chWrHtumLc"]

# get predictions
predictions = get_predictions(tweets)
print(predictions)

# map predictions to negative/neutral/positive
sentiment_mapping = {
    0: 'negative',
    1: 'neutral',
    2: 'positive'
}

predictions = [sentiment_mapping[x] for x in predictions]
print(predictions)

"""Now let's use the whole dataset."""

# read data into a dataframe and only keep the tweet_id (id), text,  author username, and date of tweet (created_at)
df = pd.read_json('workshop_tweets.json', lines=True)
df['username'] = df['author'].apply(lambda x: x['username'])
df = df[['id', 'text', 'username', 'created_at']]

# convert pandas to huggingface Dataset & tokenize
df = datasets.Dataset.from_pandas(df)
df = df.map(lambda e: tokenizer(e['text'], truncation=True), batched=True)

# make predicitons
output = trainer.predict(df)
predictions = np.argmax(output.predictions, axis=1)

# recast to pandas for easier visualizations
df = df.to_pandas()
df['sentiment'] = predictions

""" We now are going to consider the distribution of tweets according to their sentiment for each country's government-opposition pair"""

# consider only UK
df_uk = df[df['username'].isin(['BorisJohnson', 'Keir_Starmer'])]

plot_uk = df_uk.groupby('sentiment')['username'].value_counts()
for idx in plot_uk.index:
    user_count = len(df_uk[df_uk['username'] == idx[1]])
    plot_uk.loc[idx] = (plot_uk.loc[idx]/user_count) * 100

ax = plot_uk.unstack().plot(figsize=(12,8), kind='bar',  xlabel='', legend=True, ylabel='Tweets %',  width=0.4)
ax.set_xticklabels(['Negative', 'Neutral', 'Positive'],rotation=0)

# consider only Australia
df_aus = df[df['username'].isin(['AlboMP', 'ScottMorrisonMP'])]

plot_aus = df_aus.groupby('sentiment')['username'].value_counts()
for idx in plot_aus.index:
    user_count = len(df_aus[df_aus['username'] == idx[1]])
    plot_aus.loc[idx] = (plot_aus.loc[idx]/user_count) * 100

ax = plot_aus.unstack().plot(figsize=(12,8), kind='bar',  xlabel='', legend=True, ylabel='Tweets %',  width=0.4)
ax.set_xticklabels(['Negative', 'Neutral', 'Positive'],rotation=0)

"""It is important to note that for Australia Anthony Albanese was elected prime minister on May 23 and Scott Morrison previously held that office. It is interesting to explore how their tweets sentiment changes through time."""

df_aus['month'] = df_aus['created_at'].dt.strftime('%m')

# Consider only negative and positive sentiments
to_plot = (df_aus.groupby(['month','username'])['sentiment'].value_counts(normalize=True)*100).unstack().unstack().fillna(0)
to_plot[[(0, 'AlboMP'), (0, 'ScottMorrisonMP'), (2, 'AlboMP'), (2, 'ScottMorrisonMP')]].plot(figsize=(19,12),
                                                                                             color = ['red', 'red', 'blue', 'blue'],
                                                                                             style=['-','--','-','--'],
                                                                                             ylabel='Tweets %')

plt.legend(title='',labels=['AlboMP: negative', 'ScottMorrisonMP: negative', 'AlboMP: positive','ScottMorrisonMP: positive'])

